{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import poisson, gamma, dirichlet, multinomial\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = pd.read_csv('data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = x_data.iloc[:,1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_params(x_data, K,alpha):\n",
    "    N, V = x_data.shape\n",
    "    topic_assignments = np.random.randint(0, K, size=N)\n",
    "    topic_word_counts = np.zeros((K, V))\n",
    "    topic_counts = np.zeros(K)\n",
    "    lambdas = np.random.gamma(1.0, 1.0, size=(K, V))\n",
    "    pis = dirichlet.rvs(alpha * np.ones(K), size=N)\n",
    "    \n",
    "    for i in range(N):\n",
    "        topic = topic_assignments[i]\n",
    "        topic_counts[topic] += 1\n",
    "        topic_word_counts[topic] += x_data[i]\n",
    "\n",
    "    return topic_assignments, topic_word_counts, topic_counts, lambdas, pis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.76362861e-02, 8.91860559e+01])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma.rvs(a=[1,100], scale=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs_sampling(x_data, K, alpha, beta, num_iters=1000):\n",
    "    N, V = x_data.shape\n",
    "    topic_assignments, topic_word_counts, topic_counts, lambdas, pis = initialize_params(x_data, K, alpha)\n",
    "\n",
    "    for iteration in tqdm(range(num_iters)):\n",
    "        for i in range(N):\n",
    "            current_topic = topic_assignments[i]\n",
    "            topic_counts[current_topic] -= 1\n",
    "            topic_word_counts[current_topic] -= x_data[i]\n",
    "\n",
    "            log_topic_probs = np.zeros(K)\n",
    "            for k in range(K):\n",
    "                log_topic_word_prob = np.sum(poisson.logpmf(x_data[i], mu=lambdas[k]))\n",
    "                log_topic_prior_prob = np.log(pis[i, k])\n",
    "                log_topic_probs[k] = log_topic_word_prob + log_topic_prior_prob\n",
    "\n",
    "            # Subtract the max log probability to avoid numerical instability\n",
    "            log_topic_probs = log_topic_probs - np.max(log_topic_probs)\n",
    "            topic_probs = np.exp(log_topic_probs)\n",
    "            topic_probs /= topic_probs.sum()\n",
    "\n",
    "            # Sample new_topic from a multinomial distribution\n",
    "            new_topic = np.random.choice(K, p=topic_probs)\n",
    "\n",
    "            topic_assignments[i] = new_topic\n",
    "            topic_counts[new_topic] += 1\n",
    "            topic_word_counts[new_topic] += x_data[i]\n",
    "\n",
    "            # Update lambdas for the new topic\n",
    "            lambdas[new_topic] = gamma.rvs(a=topic_word_counts[new_topic] + beta, scale=1.0)\n",
    "\n",
    "            # Update pi for the current document\n",
    "            pis[i] = dirichlet.rvs(alpha + topic_counts)\n",
    "\n",
    "    return topic_assignments, topic_word_counts, topic_counts, lambdas, pis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Very Crude Pruning TODO Make this more reliable!\n",
    "\n",
    "vocabs = []\n",
    "with open('./vocab.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        vocabs.append(line.strip())\n",
    "        \n",
    "len(vocabs)\n",
    "del vocabs[8000:-1]\n",
    "del vocabs[0:10]\n",
    "len(vocabs)\n",
    "pruned_x = x_data[vocabs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2246, 7991)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:12<00:00,  6.63s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set parameters\n",
    "K = 10  # Number of topics\n",
    "alpha = 1.0  # Dirichlet prior parameter\n",
    "beta = 1.0  # Gamma prior parameter\n",
    "# num_iters = 100  # Number of iterations \n",
    "num_iters = 20 # Reduced Iterations \n",
    "\n",
    "### Take Pruned Value\n",
    "# x_data_np = x_data.values\n",
    "x_data_np = pruned_x.values\n",
    "\n",
    "\n",
    "# Run the Gibbs sampler\n",
    "print(x_data_np.shape)\n",
    "topic_assignments, topic_word_counts, topic_counts, lambdas, pis = gibbs_sampling(x_data_np, K, alpha, beta, num_iters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([183.01910867, 157.76521785, 152.50389722, ...,   0.78867308,\n",
       "         4.8711386 ,   0.4820547 ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "       [229., 252., 278., ...,   2.,   1.,   0.],\n",
       "       [358., 268., 235., ...,   2.,   0.,   1.],\n",
       "       ...,\n",
       "       [295., 288., 202., ...,   0.,   0.,   1.],\n",
       "       [114., 145., 148., ...,   1.,   2.,   0.],\n",
       "       [250., 232., 299., ...,   0.,   0.,   1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearningbase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
